{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pre-Analysis of Collected Twitter Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import col\n",
    "from pyspark.sql.functions import split, explode,expr\n",
    "from pyspark.sql.functions import udf\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import count\n",
    "from pyspark.sql.functions import countDistinct\n",
    "import pandas as pd\n",
    "from pyspark import SparkContext\n",
    "SparkContext.setSystemProperty('spark.executor.memory', '2g')\n",
    "sc = SparkContext(\"local\", \"App Name\")\n",
    "spark = SparkSession.builder.getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- coordinates: struct (nullable = true)\n",
      " |    |-- coordinates: array (nullable = true)\n",
      " |    |    |-- element: double (containsNull = true)\n",
      " |    |-- type: string (nullable = true)\n",
      " |-- date: string (nullable = true)\n",
      " |-- favorite_count: long (nullable = true)\n",
      " |-- followers_count: long (nullable = true)\n",
      " |-- friends_count: long (nullable = true)\n",
      " |-- hashtags: array (nullable = true)\n",
      " |    |-- element: struct (containsNull = true)\n",
      " |    |    |-- indices: array (nullable = true)\n",
      " |    |    |    |-- element: long (containsNull = true)\n",
      " |    |    |-- text: string (nullable = true)\n",
      " |-- influencer: long (nullable = true)\n",
      " |-- is_quote_status: boolean (nullable = true)\n",
      " |-- is_verified: boolean (nullable = true)\n",
      " |-- location: string (nullable = true)\n",
      " |-- original_tweet: long (nullable = true)\n",
      " |-- place: struct (nullable = true)\n",
      " |    |-- bounding_box: struct (nullable = true)\n",
      " |    |    |-- coordinates: array (nullable = true)\n",
      " |    |    |    |-- element: array (containsNull = true)\n",
      " |    |    |    |    |-- element: array (containsNull = true)\n",
      " |    |    |    |    |    |-- element: double (containsNull = true)\n",
      " |    |    |-- type: string (nullable = true)\n",
      " |    |-- country: string (nullable = true)\n",
      " |    |-- country_code: string (nullable = true)\n",
      " |    |-- full_name: string (nullable = true)\n",
      " |    |-- id: string (nullable = true)\n",
      " |    |-- name: string (nullable = true)\n",
      " |    |-- place_type: string (nullable = true)\n",
      " |    |-- url: string (nullable = true)\n",
      " |-- quoted_status_id: long (nullable = true)\n",
      " |-- reply_count: long (nullable = true)\n",
      " |-- retweet_count: long (nullable = true)\n",
      " |-- text: string (nullable = true)\n",
      " |-- timestamp: string (nullable = true)\n",
      " |-- tweet_date: string (nullable = true)\n",
      " |-- tweet_lang: string (nullable = true)\n",
      " |-- userId: long (nullable = true)\n",
      " |-- user_descr: string (nullable = true)\n",
      " |-- user_name: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Load tweets as Dataframe to Spark\n",
    "tweetsDF = spark.read.json(\"file:///Users/Laith/Downloads/tweetdata.json\")\n",
    "\n",
    "#Print the schema/data structure in a tree format\n",
    "tweetsDF.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Understanding the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------User Location Counting --------------------------------\n",
      "+--------------+-----+\n",
      "|       country|count|\n",
      "+--------------+-----+\n",
      "|          null|29480|\n",
      "|United Kingdom|  293|\n",
      "| United States|   64|\n",
      "|        Italia|   21|\n",
      "|   Royaume-Uni|   16|\n",
      "|        Espa√±a|   12|\n",
      "|         India|   10|\n",
      "|        Canada|    8|\n",
      "|     Australia|    6|\n",
      "|        Hellas|    6|\n",
      "|       Ireland|    5|\n",
      "|        Brasil|    5|\n",
      "|   Deutschland|    5|\n",
      "|       Germany|    5|\n",
      "|        France|    5|\n",
      "|      Malaysia|    4|\n",
      "|       Nigeria|    4|\n",
      "|         Spain|    3|\n",
      "|        Mexico|    3|\n",
      "|       Ecuador|    2|\n",
      "+--------------+-----+\n",
      "only showing top 20 rows\n",
      "\n",
      "+--------------------+-----+\n",
      "|            location|count|\n",
      "+--------------------+-----+\n",
      "|                null|10337|\n",
      "|     London, England|  646|\n",
      "|              London|  511|\n",
      "|      United Kingdom|  416|\n",
      "|England, United K...|  336|\n",
      "|                  UK|  313|\n",
      "|       United States|  225|\n",
      "|              France|  161|\n",
      "|             England|  143|\n",
      "| South West, England|  128|\n",
      "| Manchester, England|  110|\n",
      "|              Italia|   99|\n",
      "|                 USA|   98|\n",
      "|Scotland, United ...|   79|\n",
      "|            Scotland|   75|\n",
      "|          Texas, USA|   73|\n",
      "|       Paris, France|   71|\n",
      "|   Glasgow, Scotland|   70|\n",
      "|        Florida, USA|   68|\n",
      "|          London, UK|   65|\n",
      "| North West, England|   61|\n",
      "+--------------------+-----+\n",
      "only showing top 21 rows\n",
      "\n",
      "+--------------------+-----+\n",
      "|            location|count|\n",
      "+--------------------+-----+\n",
      "|     London, England|  646|\n",
      "|              London|  511|\n",
      "|      United Kingdom|  416|\n",
      "|England, United K...|  336|\n",
      "|                  UK|  313|\n",
      "|             England|  143|\n",
      "| South West, England|  128|\n",
      "| Manchester, England|  110|\n",
      "|Scotland, United ...|   79|\n",
      "|            Scotland|   75|\n",
      "+--------------------+-----+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(\"---------------------User Location Counting --------------------------------\")\n",
    "#Get top 20 places \n",
    "tweetsDF.select(\"place.country\").groupBy(\"country\").count().sort(col(\"count\").desc()).show(20)\n",
    "\n",
    "#Get top 21 user locations\n",
    "tweetsDF.groupBy(\"location\").count().sort(col(\"count\").desc()).show(21)\n",
    "#Get top 10 locations within the UK\n",
    "tweetsDF.groupBy(\"location\").count().sort(col(\"count\").desc()).where(\"location LIKE '%UK%' OR location LIKE '%London%' OR location LIKE '%United Kingdom%' OR location LIKE '%England%' OR location LIKE '%Scotland%' OR location LIKE '%Wales%' OR location LIKE '%Ireland%'\").show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------User's Languages Counting --------------------------------\n",
      "+----------+-----+\n",
      "|tweet_lang|count|\n",
      "+----------+-----+\n",
      "|        en|20811|\n",
      "|        it| 1810|\n",
      "|        fr| 1663|\n",
      "|       und| 1434|\n",
      "|        es| 1285|\n",
      "|        de|  980|\n",
      "|        nl|  796|\n",
      "|        pt|  347|\n",
      "|        ja|  320|\n",
      "|        ca|   99|\n",
      "+----------+-----+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    " #Language Counting \n",
    "print(\"---------------------User's Languages Counting --------------------------------\")\n",
    "    #Get user languages\n",
    "tweetsDF.groupBy(\"tweet_lang\").count().sort(col(\"count\").desc()).show(10)\n",
    "    #Get English tweets\n",
    "tweetsEn = tweetsDF.where(\"tweet_lang=='en'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+-----+\n",
      "|     original_tweet|count|\n",
      "+-------------------+-----+\n",
      "|               null|20596|\n",
      "|1205493508511059968|    3|\n",
      "|1205501506692304896|    2|\n",
      "|1205510619128041474|    2|\n",
      "|1205494373905031172|    2|\n",
      "|1205516927550066690|    2|\n",
      "|1205500301421056002|    2|\n",
      "|1202777589674336256|    1|\n",
      "|1205496352588881920|    1|\n",
      "|1205495271448285186|    1|\n",
      "+-------------------+-----+\n",
      "only showing top 10 rows\n",
      "\n",
      "+------------------+-----+\n",
      "|        influencer|count|\n",
      "+------------------+-----+\n",
      "|              null|20443|\n",
      "|        3131144855|   20|\n",
      "|         164226176|    7|\n",
      "|         117777690|    5|\n",
      "|         856010760|    5|\n",
      "|          80802900|    4|\n",
      "|          14291684|    4|\n",
      "|          65045121|    4|\n",
      "|745370688375099392|    3|\n",
      "|           5402612|    3|\n",
      "+------------------+-----+\n",
      "only showing top 10 rows\n",
      "\n",
      "+---------------+-----+\n",
      "|is_quote_status|count|\n",
      "+---------------+-----+\n",
      "|           true|20811|\n",
      "+---------------+-----+\n",
      "\n",
      "+-------------------+-----+\n",
      "|        reply_count|count|\n",
      "+-------------------+-----+\n",
      "|1205368801438707713| 2185|\n",
      "|1205441159805444098| 1039|\n",
      "|1205326557474103296|  759|\n",
      "|1203927100740243456|  437|\n",
      "|1205403440144429056|  362|\n",
      "|1205421989189566465|  273|\n",
      "|1205271817839095810|  233|\n",
      "|1205408483287457793|  226|\n",
      "|1205489469186609152|  211|\n",
      "|1205426773506318336|  197|\n",
      "+-------------------+-----+\n",
      "only showing top 10 rows\n",
      "\n",
      "+-------------+-----+\n",
      "|retweet_count|count|\n",
      "+-------------+-----+\n",
      "|            0|20811|\n",
      "+-------------+-----+\n",
      "\n",
      "+--------------+-----+\n",
      "|favorite_count|count|\n",
      "+--------------+-----+\n",
      "|             0|20811|\n",
      "+--------------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Check tweets that are not responses or quotes - original tweets\n",
    "tweetsEn.groupBy(\"original_tweet\").count().sort(col(\"count\").desc()).show(10)\n",
    "\n",
    "#Check Tweets that are not influenced by other tweets\n",
    "tweetsEn.groupBy(\"influencer\").count().sort(col(\"count\").desc()).show(10)\n",
    "\n",
    "#Check tweets that quotes other people\n",
    "tweetsEn.groupBy(\"is_quote_status\").count().sort(col(\"count\").desc()).show()\n",
    "\n",
    "#Check if influence data makes sense\n",
    "tweetsEn.groupBy(\"reply_count\").count().sort(col(\"count\").desc()).show(10)\n",
    "tweetsEn.groupBy(\"retweet_count\").count().sort(col(\"count\").desc()).show(10)\n",
    "tweetsEn.groupBy(\"favorite_count\").count().sort(col(\"count\").desc()).show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-----+\n",
      "|tweet_lang|count|\n",
      "+----------+-----+\n",
      "|        en|19116|\n",
      "+----------+-----+\n",
      "\n",
      "+---------------+-----+\n",
      "|followers_count|count|\n",
      "+---------------+-----+\n",
      "|            186|   91|\n",
      "|             52|   43|\n",
      "|             54|   38|\n",
      "|            155|   36|\n",
      "|             75|   36|\n",
      "|             65|   35|\n",
      "|             66|   35|\n",
      "|             73|   34|\n",
      "|            147|   33|\n",
      "|            154|   32|\n",
      "+---------------+-----+\n",
      "only showing top 10 rows\n",
      "\n",
      "+-----------+-----+\n",
      "|is_verified|count|\n",
      "+-----------+-----+\n",
      "|       true|  297|\n",
      "|      false|18819|\n",
      "+-----------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#drop columns\n",
    "tweetsDC = tweetsEn.drop('retweet_count', 'favorite_count', 'coordinates', 'tweet_date', 'is_quote_status')\n",
    "#tweetsDC.printSchema()\n",
    "#drop users with less than 50 followers\n",
    "tweetsFC = tweetsDC.where(\"followers_count>=50\")\n",
    "tweetsFC.groupBy(\"tweet_lang\").count().sort(col(\"count\").desc()).show(10)\n",
    "tweetsFC.groupBy(\"followers_count\").count().sort(col(\"count\").desc()).show(10)\n",
    "tweetsFC.groupBy(\"is_verified\").count().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-----+\n",
      "|                date|count|\n",
      "+--------------------+-----+\n",
      "|Fri May 24 17:22:...|   76|\n",
      "|Fri Jul 13 22:29:...|   24|\n",
      "|Thu Aug 08 12:56:...|   23|\n",
      "|Wed Jul 08 14:08:...|   16|\n",
      "|Sat Jan 26 08:59:...|   16|\n",
      "|Mon Jul 09 11:00:...|   15|\n",
      "|Thu Jun 02 14:10:...|   15|\n",
      "|Fri Apr 20 10:49:...|   15|\n",
      "|Sun Feb 06 10:37:...|   15|\n",
      "|Fri Aug 05 13:14:...|   15|\n",
      "|Mon Jan 15 12:51:...|   14|\n",
      "|Sat Nov 03 10:44:...|   14|\n",
      "|Wed Mar 25 02:53:...|   13|\n",
      "|Thu Dec 11 22:59:...|   13|\n",
      "|Fri Aug 03 08:13:...|   13|\n",
      "|Tue Feb 28 19:33:...|   13|\n",
      "|Thu Jan 12 17:43:...|   11|\n",
      "|Mon Sep 09 15:57:...|   11|\n",
      "|Tue Feb 23 01:40:...|   11|\n",
      "|Wed Aug 29 20:27:...|   10|\n",
      "+--------------------+-----+\n",
      "only showing top 20 rows\n",
      "\n",
      "+-------------------+-----+\n",
      "|        reply_count|count|\n",
      "+-------------------+-----+\n",
      "|1205368801438707713| 1952|\n",
      "|1205441159805444098|  969|\n",
      "|1205326557474103296|  695|\n",
      "|1203927100740243456|  427|\n",
      "|1205403440144429056|  343|\n",
      "|1205421989189566465|  253|\n",
      "|1205408483287457793|  206|\n",
      "|1205271817839095810|  194|\n",
      "|1205489469186609152|  190|\n",
      "|1205426773506318336|  188|\n",
      "|1205490491535626245|  182|\n",
      "|1205513403466502144|  180|\n",
      "|1205266744002142208|  175|\n",
      "|1205482405567639553|  175|\n",
      "|1205272337752436736|  171|\n",
      "|1205399373322080256|  145|\n",
      "|1205246679835910145|  143|\n",
      "|1205435581402099713|  142|\n",
      "|1205335470302994433|  137|\n",
      "|1205260960715464704|  128|\n",
      "+-------------------+-----+\n",
      "only showing top 20 rows\n",
      "\n",
      "root\n",
      " |-- date: string (nullable = true)\n",
      " |-- followers_count: long (nullable = true)\n",
      " |-- friends_count: long (nullable = true)\n",
      " |-- hashtags: array (nullable = true)\n",
      " |    |-- element: struct (containsNull = true)\n",
      " |    |    |-- indices: array (nullable = true)\n",
      " |    |    |    |-- element: long (containsNull = true)\n",
      " |    |    |-- text: string (nullable = true)\n",
      " |-- influencer: long (nullable = true)\n",
      " |-- is_verified: boolean (nullable = true)\n",
      " |-- location: string (nullable = true)\n",
      " |-- original_tweet: long (nullable = true)\n",
      " |-- place: struct (nullable = true)\n",
      " |    |-- bounding_box: struct (nullable = true)\n",
      " |    |    |-- coordinates: array (nullable = true)\n",
      " |    |    |    |-- element: array (containsNull = true)\n",
      " |    |    |    |    |-- element: array (containsNull = true)\n",
      " |    |    |    |    |    |-- element: double (containsNull = true)\n",
      " |    |    |-- type: string (nullable = true)\n",
      " |    |-- country: string (nullable = true)\n",
      " |    |-- country_code: string (nullable = true)\n",
      " |    |-- full_name: string (nullable = true)\n",
      " |    |-- id: string (nullable = true)\n",
      " |    |-- name: string (nullable = true)\n",
      " |    |-- place_type: string (nullable = true)\n",
      " |    |-- url: string (nullable = true)\n",
      " |-- quoted_status_id: long (nullable = true)\n",
      " |-- reply_count: long (nullable = true)\n",
      " |-- text: string (nullable = true)\n",
      " |-- timestamp: string (nullable = true)\n",
      " |-- userId: long (nullable = true)\n",
      " |-- user_descr: string (nullable = true)\n",
      " |-- user_name: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "tweetsFC.groupBy(\"date\").count().sort(col(\"count\").desc()).show(20)\n",
    "#Choose tweets of users who were created before Dec 2019 \n",
    "tweetsNC = tweetsFC.where(\"date NOT LIKE '%2019' OR date NOT LIKE '%Dec%'\")\n",
    "\n",
    "#Choose tweets of users who were created before Nov 2019 \n",
    "tweetsNC = tweetsNC.where(\"date NOT LIKE '%2019' OR date NOT LIKE '%Nov%'\")\n",
    "#tweetsNC.groupBy(\"tweet_lang\").count().sort(col(\"count\").desc()).show()\n",
    "tweetsNC.groupBy(\"reply_count\").count().sort(col(\"count\").desc()).show()\n",
    "tweetsNC = tweetsNC.drop('tweet_lang')\n",
    "tweetsNC.printSchema()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Basic Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+-----+\n",
      "|is_verified|count|\n",
      "+-----------+-----+\n",
      "|       true|  297|\n",
      "|      false|18622|\n",
      "+-----------+-----+\n",
      "\n",
      "+-------------------+-----+\n",
      "|               text|count|\n",
      "+-------------------+-----+\n",
      "|             Brexit|  474|\n",
      "|                 UK|  104|\n",
      "|              leave|   64|\n",
      "|            fishing|   63|\n",
      "|         reclaiming|   62|\n",
      "|             GE2019|   62|\n",
      "|    GeneralElection|   55|\n",
      "|             brexit|   51|\n",
      "|          Trump2020|   39|\n",
      "|    BritishElection|   38|\n",
      "|            goodbye|   37|\n",
      "|          socialist|   37|\n",
      "|      GetBrexitDone|   37|\n",
      "|                NWO|   37|\n",
      "|          GoodGrief|   37|\n",
      "|       BorisJohnson|   37|\n",
      "|            liberal|   37|\n",
      "|GeneralElection2019|   36|\n",
      "|           IndyRef2|   34|\n",
      "|     UKelection2019|   30|\n",
      "+-------------------+-----+\n",
      "only showing top 20 rows\n",
      "\n",
      "+--------------+-----+\n",
      "|     user_name|count|\n",
      "+--------------+-----+\n",
      "|   TaraJewell6|   76|\n",
      "|cloudwanderer3|   24|\n",
      "|   SaraPadmore|   23|\n",
      "|Carter7Raymond|   16|\n",
      "|    z_chrissie|   16|\n",
      "|   billoislove|   15|\n",
      "|      oldbid45|   15|\n",
      "|       pjpaton|   15|\n",
      "|   donifordace|   15|\n",
      "|  didierdelmer|   15|\n",
      "+--------------+-----+\n",
      "only showing top 10 rows\n",
      "\n",
      "+-------------+\n",
      "|count(userId)|\n",
      "+-------------+\n",
      "|        18919|\n",
      "+-------------+\n",
      "\n",
      "+----------------------+\n",
      "|count(DISTINCT userId)|\n",
      "+----------------------+\n",
      "|                 14763|\n",
      "+----------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#What is trending right now? top 20 popular hashtags \n",
    "\n",
    "tweetsNC.groupBy(\"is_verified\").count().show()\n",
    "\n",
    "tweetsNC.select(explode(col(\"hashtags\")).alias(\"hashtags_list\"))\\\n",
    "            .groupBy(\"hashtags_list.text\")\\\n",
    "            .count().sort(col(\"count\").desc())\\\n",
    "            .show(20)\n",
    "\n",
    "    \n",
    "#How many users?    \n",
    "tweetsNC.groupBy(\"user_name\").count().sort(col(\"count\").desc()).show(10)\n",
    "\n",
    "#tweetsNC.describe(['userId']).show()\n",
    "#print(\"---------------------number of tweets --------------------------------\")\n",
    "tweetsNC.agg(count(\"userId\")).show()\n",
    "#print(\"---------------------User of distinct users --------------------------------\")\n",
    "tweetsNC.agg(countDistinct(\"userId\")).show()\n",
    "\n",
    "\n",
    "#top 20 popular Tweets\n",
    "    \n",
    "#tweets with emotions \n",
    "#tweetsNC.filter(col(\"text\").like(\":\")).show(10)\n",
    "#tweetsNC.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweetsNC = tweetsNC.drop('place', 'timestamps', 'user_name', 'influencer', 'timestamp', 'user_descr', 'original_tweet', 'date', 'quoted_status_id')\n",
    "#Replace Missing Values and then remove all tweets from users in locations outside the UK\n",
    "tweetClean = tweetsNC.na.fill({\"location\":\"ND\"})\n",
    "\n",
    "tweetCleans = tweetClean.where(\"location NOT LIKE '%USA%'\")\n",
    "\n",
    "\n",
    "tweetCleans = tweetCleans.withColumn('location', when(tweetCleans.location.like('%England%'), 'England').otherwise(tweetCleans['location']))\n",
    "tweetCleans = tweetCleans.withColumn('location', when(tweetCleans.location.like('%Wales%'), 'Wales').otherwise(tweetCleans['location']))\n",
    "tweetCleans = tweetCleans.withColumn('location', when(tweetCleans.location.like('%Scotland%'), 'Scotland').otherwise(tweetCleans['location']))\n",
    "tweetCleans = tweetCleans.withColumn('location', when(tweetCleans.location.like('%Northern Ireland%'), 'NI').otherwise(tweetCleans['location']))\n",
    "\n",
    "tweetCleans = tweetCleans.withColumn('location', regexp_replace('location', 'United Kingdom', 'UK'))\n",
    "tweetCleans = tweetCleans.withColumn('location', regexp_replace('location', 'Great Britain', 'UK'))\n",
    "tweetCleans = tweetCleans.withColumn('location', regexp_replace('location', 'uk', 'UK'))\n",
    "tweetCleans = tweetCleans.withColumn('location', regexp_replace('location', 'London, UK', 'England'))\n",
    "tweetCleans = tweetCleans.withColumn('location', regexp_replace('location', 'Manchester', 'England'))\n",
    "tweetCleans = tweetCleans.withColumn('location', regexp_replace('location', 'London ', 'England'))\n",
    "tweetCleans = tweetCleans.withColumn('location', regexp_replace('location', 'London', 'England'))\n",
    "tweetCleans = tweetCleans.withColumn('location', regexp_replace('location', 'Yorkshire', 'England'))\n",
    "tweetCleans = tweetCleans.withColumn('location', regexp_replace('location', 'Liverpool', 'England'))\n",
    "tweetCleans = tweetCleans.withColumn('location', regexp_replace('location', 'london', 'England'))\n",
    "tweetCleans = tweetCleans.withColumn('location', regexp_replace('location', 'Cornwall', 'England'))\n",
    "tweetCleans = tweetCleans.withColumn('location', regexp_replace('location', 'Sheffield', 'England'))\n",
    "tweetCleans = tweetCleans.withColumn('location', regexp_replace('location', 'Bristol', 'England'))\n",
    "tweetCleans = tweetCleans.withColumn('location', regexp_replace('location', 'Essex', 'England'))\n",
    "tweetCleans = tweetCleans.withColumn('location', regexp_replace('location', 'oxford', 'England'))\n",
    "tweetCleans = tweetCleans.withColumn('location', regexp_replace('location', 'Sussex', 'England'))\n",
    "tweetCleans = tweetCleans.withColumn('location', regexp_replace('location', 'Derby', 'England'))\n",
    "tweetCleans = tweetCleans.withColumn('location', regexp_replace('location', 'West Sussex', 'England'))\n",
    "tweetCleans = tweetCleans.withColumn('location', regexp_replace('location', 'Leeds', 'England'))\n",
    "tweetCleans = tweetCleans.withColumn('location', regexp_replace('location', 'Oxfordshire', 'England'))\n",
    "tweetCleans = tweetCleans.withColumn('location', regexp_replace('location', 'Surrey', 'England'))\n",
    "tweetCleans = tweetCleans.withColumn('location', regexp_replace('location', 'Oxford', 'England'))\n",
    "tweetCleans = tweetCleans.withColumn('location', regexp_replace('location', 'Kent', 'England'))\n",
    "tweetCleans = tweetCleans.withColumn('location', regexp_replace('location', 'Birmingham', 'England'))\n",
    "tweetCleans = tweetCleans.withColumn('location', regexp_replace('location', 'Brighton', 'England'))\n",
    "tweetCleans = tweetCleans.withColumn('location', regexp_replace('location', 'Cambridge, UK', 'England'))\n",
    "tweetCleans = tweetCleans.withColumn('location', regexp_replace('location', 'Hampshire, UK', 'England'))\n",
    "tweetCleans = tweetCleans.withColumn('location', regexp_replace('location', 'Glasgow', 'Scotland'))\n",
    "tweetCleans = tweetCleans.withColumn('location', regexp_replace('location', 'Edinburgh', 'Scotland'))\n",
    "tweetCleans = tweetCleans.withColumn('location', regexp_replace('location', 'Cardiff', 'Wales'))\n",
    "tweetCleans = tweetCleans.withColumn('location', regexp_replace('location', 'Belfast', 'NI'))\n",
    "#tweetsClean = tweetCleans.select(\"*\").where(\"location LIKE 'UK' OR location LIKE 'UK' OR location LIKE 'England' OR location LIKE 'NI' OR location LIKE 'Scotland' OR location LIKE 'Wales' \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------+\n",
      "|count(location)|\n",
      "+---------------+\n",
      "|          18240|\n",
      "+---------------+\n",
      "\n",
      "+------------------------+\n",
      "|count(DISTINCT location)|\n",
      "+------------------------+\n",
      "|                    4683|\n",
      "+------------------------+\n",
      "\n",
      "+--------------------+-----+\n",
      "|            location|count|\n",
      "+--------------------+-----+\n",
      "|                  ND| 5382|\n",
      "|             England| 3409|\n",
      "|                  UK|  688|\n",
      "|            Scotland|  478|\n",
      "|               Wales|  237|\n",
      "|       United States|  194|\n",
      "|         England, UK|   76|\n",
      "|                  NI|   58|\n",
      "|      Washington, DC|   46|\n",
      "|        New York, NY|   36|\n",
      "|             Ireland|   31|\n",
      "|               Earth|   31|\n",
      "|              Canada|   28|\n",
      "|        West England|   24|\n",
      "|     Laurelind√≥renan|   24|\n",
      "|        Planet Earth|   23|\n",
      "|    Toronto, Ontario|   22|\n",
      "|          England UK|   22|\n",
      "|               Texas|   22|\n",
      "|            England |   22|\n",
      "|              Europe|   22|\n",
      "|         Chicago, IL|   22|\n",
      "|      European Union|   21|\n",
      "|            New York|   21|\n",
      "|               India|   19|\n",
      "|         Houston, TX|   19|\n",
      "|       South England|   19|\n",
      "|     Dublin, Ireland|   18|\n",
      "|           EnglandUK|   16|\n",
      "|         Switzerland|   16|\n",
      "|     Los Angeles, CA|   15|\n",
      "|      in your dreams|   15|\n",
      "|   Brussels, Belgium|   15|\n",
      "|Dublin City, Ireland|   15|\n",
      "|           Neverland|   15|\n",
      "|          Tarragona.|   14|\n",
      "|          Austin, TX|   14|\n",
      "|    Hackney, England|   14|\n",
      "| Berlin, Deutschland|   14|\n",
      "|       New York City|   14|\n",
      "|                 NYC|   14|\n",
      "|     European Union |   13|\n",
      "|        East England|   13|\n",
      "|              Berlin|   13|\n",
      "|     England/England|   13|\n",
      "|        Brooklyn, NY|   13|\n",
      "|             she/her|   12|\n",
      "|       San Diego, CA|   12|\n",
      "|              Dublin|   12|\n",
      "|           Hong Kong|   12|\n",
      "|         Deutschland|   12|\n",
      "|     Berlin, Germany|   12|\n",
      "| European Union üá™üá∫|   11|\n",
      "|       Paris, France|   11|\n",
      "| Always on your mind|   11|\n",
      "|             Germany|   10|\n",
      "|     Ontario, Canada|   10|\n",
      "|         Seattle, WA|   10|\n",
      "|       Washington DC|   10|\n",
      "|             Cumbria|    9|\n",
      "|          California|    9|\n",
      "|          Everywhere|    9|\n",
      "|              France|    9|\n",
      "|                  EU|    9|\n",
      "|Long Compton, Sou...|    9|\n",
      "|      Brent, England|    9|\n",
      "|    Philadelphia, PA|    9|\n",
      "|  Islington, England|    9|\n",
      "|    Croydon, England|    9|\n",
      "|            England\n",
      "|    9|\n",
      "|            Brussels|    9|\n",
      "|         Phoenix, AZ|    9|\n",
      "|                York|    9|\n",
      "|Kingston upon Tha...|    9|\n",
      "|Caterham, England...|    9|\n",
      "|              Boston|    9|\n",
      "|Coming for your s...|    9|\n",
      "|At the Prime Meri...|    9|\n",
      "|             Finland|    8|\n",
      "|           Wakefield|    8|\n",
      "|           Australia|    8|\n",
      "|               Mars |    8|\n",
      "|             Toronto|    8|\n",
      "|           Miami, FL|    8|\n",
      "| Newcastle upon Tyne|    8|\n",
      "|People's Republic...|    8|\n",
      "|          Nottingham|    8|\n",
      "|        Englandshire|    8|\n",
      "|            Hastings|    8|\n",
      "|      Pittsburgh, PA|    8|\n",
      "|    New Delhi, India|    8|\n",
      "|     Santana/England|    8|\n",
      "|          Shropshire|    8|\n",
      "|          manchester|    8|\n",
      "|             Chicago|    8|\n",
      "|       Baltimore, MD|    8|\n",
      "|                Hull|    8|\n",
      "|               Devon|    8|\n",
      "|                hull|    7|\n",
      "|             Florida|    7|\n",
      "+--------------------+-----+\n",
      "only showing top 100 rows\n",
      "\n",
      "+---------------+-------------+--------+-----------+-------------------+-------------------+----------------------------------------------------------+-------------------+\n",
      "|followers_count|friends_count|hashtags|is_verified|location           |reply_count        |text                                                      |userId             |\n",
      "+---------------+-------------+--------+-----------+-------------------+-------------------+----------------------------------------------------------+-------------------+\n",
      "|3987           |1664         |[]      |false      |ND                 |1205246530136862721|Looks like your hairline is leaving before Brexit arrives.|1114951427607158786|\n",
      "|2387           |4996         |[]      |false      |Blackheath, England|1205470817959776257|Urgh                                                      |351883595          |\n",
      "+---------------+-------------+--------+-----------+-------------------+-------------------+----------------------------------------------------------+-------------------+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "tweetsClean = tweetCleans\n",
    "tweetsClean.agg(count(\"location\")).show()\n",
    "tweetsClean.agg(countDistinct(\"location\")).show()\n",
    "tweetsClean.groupBy(\"location\").count().sort(col(\"count\").desc()).show(100)\n",
    "tweetsClean.show(2, False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Filtering tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweetsClean.coalesce(1).write.json(\"file:///Users/Laith/Downloads/features_tweets.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- followers_count: long (nullable = true)\n",
      " |-- friends_count: long (nullable = true)\n",
      " |-- hashtags: array (nullable = true)\n",
      " |    |-- element: struct (containsNull = true)\n",
      " |    |    |-- indices: array (nullable = true)\n",
      " |    |    |    |-- element: long (containsNull = true)\n",
      " |    |    |-- text: string (nullable = true)\n",
      " |-- is_verified: boolean (nullable = true)\n",
      " |-- location: string (nullable = true)\n",
      " |-- reply_count: long (nullable = true)\n",
      " |-- text: string (nullable = true)\n",
      " |-- userId: long (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Load firstClean tweets \n",
    "firstClean = spark.read.json(\"file:///Users/Laith/Downloads/firstClean.json\")\n",
    "\n",
    "#Print the schema/data structure in a tree format\n",
    "firstClean.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "firstClean = firstClean.where(\"location NOT LIKE '%Dublin%'\")\n",
    "firstClean = firstClean.where(\"location NOT LIKE '%ND%'\")\n",
    "firstClean = firstClean.where(\"location NOT LIKE '%France%'\")\n",
    "firstClean = firstClean.where(\"location NOT LIKE '%United States%'\")\n",
    "firstClean = firstClean.where(\"location NOT LIKE 'Ireland%'\")\n",
    "firstClean = firstClean.where(\"location NOT LIKE '%Washington%'\")\n",
    "firstClean = firstClean.where(\"location NOT LIKE '%New York%'\")\n",
    "firstClean = firstClean.where(\"location NOT LIKE '%Canada%'\")\n",
    "firstClean = firstClean.where(\"location NOT LIKE '%Chicago%'\")\n",
    "firstClean = firstClean.where(\"location NOT LIKE '%Texas%'\")\n",
    "firstClean = firstClean.where(\"location NOT LIKE '%Europe%'\")\n",
    "firstClean = firstClean.where(\"location NOT LIKE '%Toronto%'\")\n",
    "firstClean = firstClean.where(\"location NOT LIKE '%Earth%'\")\n",
    "firstClean = firstClean.where(\"location NOT LIKE '%Laurelind√≥renan%'\")\n",
    "firstClean = firstClean.where(\"location NOT LIKE '%India%'\")\n",
    "firstClean = firstClean.where(\"location NOT LIKE '%Houston%'\")\n",
    "firstClean = firstClean.where(\"location NOT LIKE '%Switzerland%'\")\n",
    "firstClean = firstClean.where(\"location NOT LIKE '%Germany%'\")\n",
    "firstClean = firstClean.where(\"location NOT LIKE '%Italy%'\")\n",
    "firstClean = firstClean.where(\"location NOT LIKE '%Los Angeles%'\")\n",
    "firstClean = firstClean.where(\"location NOT LIKE '%Belgium%'\")\n",
    "firstClean = firstClean.where(\"location NOT LIKE '%dreams%'\")\n",
    "firstClean = firstClean.where(\"location NOT LIKE '%Neverland%'\")\n",
    "firstClean = firstClean.where(\"location NOT LIKE '%NYC%'\")\n",
    "firstClean = firstClean.where(\"location NOT LIKE '%Berlin%'\")\n",
    "firstClean = firstClean.where(\"location NOT LIKE '%Tarragona%'\")\n",
    "firstClean = firstClean.where(\"location NOT LIKE '%TX%'\")\n",
    "firstClean = firstClean.where(\"location NOT LIKE '%NY%'\")\n",
    "firstClean = firstClean.where(\"location NOT LIKE '%CA%'\")\n",
    "firstClean = firstClean.where(\"location NOT LIKE '%Deutschland%'\")\n",
    "firstClean = firstClean.where(\"location NOT LIKE '%Hong Kong%'\")\n",
    "firstClean = firstClean.where(\"location NOT LIKE '%she/her%'\")\n",
    "firstClean = firstClean.where(\"location NOT LIKE '%AZ%'\")\n",
    "firstClean = firstClean.where(\"location NOT LIKE '%At the%'\")\n",
    "firstClean = firstClean.where(\"location NOT LIKE '%EU%'\")\n",
    "firstClean = firstClean.where(\"location NOT LIKE '%PA%'\")\n",
    "firstClean = firstClean.where(\"location NOT LIKE '%Everywhere%'\")\n",
    "firstClean = firstClean.where(\"location NOT LIKE '%Finland%'\")\n",
    "firstClean = firstClean.where(\"location NOT LIKE '%Boston%'\")\n",
    "firstClean = firstClean.where(\"location NOT LIKE '%FL%'\")\n",
    "firstClean = firstClean.where(\"location NOT LIKE '%California%'\")\n",
    "firstClean = firstClean.where(\"location NOT LIKE '%WA%'\")\n",
    "firstClean = firstClean.where(\"location NOT LIKE '%Always%'\")\n",
    "firstClean = firstClean.where(\"location NOT LIKE '%Brussels%'\")\n",
    "firstClean = firstClean.where(\"location NOT LIKE '%Coming for%'\")\n",
    "firstClean = firstClean.where(\"location NOT LIKE '%Australia%'\")\n",
    "firstClean = firstClean.where(\"location NOT LIKE '%Mars%'\")\n",
    "firstClean = firstClean.where(\"location NOT LIKE '%MD%'\")\n",
    "firstClean = firstClean.where(\"location NOT LIKE '%Global%'\")\n",
    "firstClean = firstClean.where(\"location NOT LIKE '%Forever%'\")\n",
    "firstClean = firstClean.where(\"location NOT LIKE '%NV%'\")\n",
    "firstClean = firstClean.where(\"location NOT LIKE '%Illinois%'\")\n",
    "firstClean = firstClean.where(\"location NOT LIKE '%KY%'\")\n",
    "firstClean = firstClean.where(\"location NOT LIKE '%NoNazi%'\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------+\n",
      "|count(location)|\n",
      "+---------------+\n",
      "|          10780|\n",
      "+---------------+\n",
      "\n",
      "+------------------------+\n",
      "|count(DISTINCT location)|\n",
      "+------------------------+\n",
      "|                    3923|\n",
      "+------------------------+\n",
      "\n",
      "+--------------------+-----+\n",
      "|            location|count|\n",
      "+--------------------+-----+\n",
      "|             England| 3409|\n",
      "|                  UK|  688|\n",
      "|            Scotland|  478|\n",
      "|               Wales|  237|\n",
      "|         England, UK|   76|\n",
      "|                  NI|   58|\n",
      "|        West England|   24|\n",
      "|          England UK|   22|\n",
      "|            England |   22|\n",
      "|       South England|   19|\n",
      "|           EnglandUK|   16|\n",
      "|    Hackney, England|   14|\n",
      "|        East England|   13|\n",
      "|     England/England|   13|\n",
      "|             Cumbria|    9|\n",
      "|    Croydon, England|    9|\n",
      "|Long Compton, Sou...|    9|\n",
      "|  Islington, England|    9|\n",
      "|Kingston upon Tha...|    9|\n",
      "|Caterham, England...|    9|\n",
      "+--------------------+-----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "firstClean.agg(count(\"location\")).show()\n",
    "firstClean.agg(countDistinct(\"location\")).show()\n",
    "firstClean.groupBy(\"location\").count().sort(col(\"count\").desc()).show(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------+\n",
      "|count(location)|\n",
      "+---------------+\n",
      "|          10780|\n",
      "+---------------+\n",
      "\n",
      "+------------------------+\n",
      "|count(DISTINCT location)|\n",
      "+------------------------+\n",
      "|                    3193|\n",
      "+------------------------+\n",
      "\n",
      "+--------------------------+-----+\n",
      "|location                  |count|\n",
      "+--------------------------+-----+\n",
      "|England                   |4365 |\n",
      "|UK                        |1034 |\n",
      "|Scotland                  |501  |\n",
      "|Wales                     |245  |\n",
      "|NI                        |77   |\n",
      "|Cumbria                   |9    |\n",
      "|Long Compton, South Warks |9    |\n",
      "|York                      |9    |\n",
      "|Nottingham                |8    |\n",
      "|Devon                     |8    |\n",
      "|Hull                      |8    |\n",
      "|manchester                |8    |\n",
      "|Wakefield                 |8    |\n",
      "|Shropshire                |8    |\n",
      "|Newcastle upon Tyne       |8    |\n",
      "|Hastings                  |8    |\n",
      "|People's Republic of China|8    |\n",
      "|Tx                        |7    |\n",
      "|Whitstable                |7    |\n",
      "|South Carolina            |7    |\n",
      "|Melbourne, Victoria       |7    |\n",
      "|Lagos, Nigeria            |7    |\n",
      "|Dorset                    |7    |\n",
      "| Dorset, Ireland, Spain   |7    |\n",
      "|hull                      |7    |\n",
      "|Michigan                  |7    |\n",
      "|The Netherlands           |7    |\n",
      "|Up North                  |7    |\n",
      "|Paris                     |7    |\n",
      "|America                   |7    |\n",
      "|wigan                     |7    |\n",
      "|Florida                   |7    |\n",
      "|england                   |6    |\n",
      "|Russia                    |6    |\n",
      "|Florence, Tuscany         |6    |\n",
      "|Worcestershire            |6    |\n",
      "|he/him                    |6    |\n",
      "|Virginia                  |6    |\n",
      "|Uk                        |6    |\n",
      "|English Midlands          |6    |\n",
      "|Suffolk                   |6    |\n",
      "|Cheshire                  |6    |\n",
      "|Here                      |6    |\n",
      "|University of Stirling    |6    |\n",
      "|Epsom, South East         |6    |\n",
      "|Citizen of Nowhere        |6    |\n",
      "|Connecticut               |6    |\n",
      "|Basingstoke               |6    |\n",
      "|The outer reaches.        |6    |\n",
      "|citizen of the world      |6    |\n",
      "|Southampton               |6    |\n",
      "|Oslo, Norway              |6    |\n",
      "|Abuja, Nigeria            |6    |\n",
      "|San Francisco             |6    |\n",
      "|Inverness                 |6    |\n",
      "|Bournemouth               |6    |\n",
      "|Tennessee                 |6    |\n",
      "|Newport, Isle of Wight    |6    |\n",
      "|Japan                     |6    |\n",
      "|Columbus, OH              |6    |\n",
      "|Berkshire                 |6    |\n",
      "|Nigeria                   |5    |\n",
      "|Finsbury Park             |5    |\n",
      "|North America             |5    |\n",
      "|South                     |5    |\n",
      "|Missouri                  |5    |\n",
      "|united kingdom            |5    |\n",
      "|Podunkville               |5    |\n",
      "|Portsmouth                |5    |\n",
      "|Croydon                   |5    |\n",
      "|Brideshead                |5    |\n",
      "|Coningsby, Lincs          |5    |\n",
      "|Reading                   |5    |\n",
      "|Aberdeenshire             |5    |\n",
      "|Staffordshire             |5    |\n",
      "|Prague, Czech Republic    |5    |\n",
      "|Spain                     |5    |\n",
      "|not in a vote remain area |5    |\n",
      "|Croydon                   |5    |\n",
      "|chesterfield              |5    |\n",
      "|She/her                   |5    |\n",
      "|Northumberland            |5    |\n",
      "|nowhere man.              |5    |\n",
      "|Cork, Ireland             |5    |\n",
      "|LDN                       |5    |\n",
      "|Home                      |5    |\n",
      "|Universe                  |5    |\n",
      "|Andalusia, Spain          |5    |\n",
      "|The World                 |5    |\n",
      "|Herefordshire             |5    |\n",
      "|Moscow,Russia             |5    |\n",
      "|Galway, Ireland           |5    |\n",
      "|glasgow                   |5    |\n",
      "|Wirral                    |5    |\n",
      "|America                   |5    |\n",
      "|Somerset                  |4    |\n",
      "|Mother Box                |4    |\n",
      "|Taunton Somerset          |4    |\n",
      "|Moscow, Russia            |4    |\n",
      "|southampton               |4    |\n",
      "+--------------------------+-----+\n",
      "only showing top 100 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#firstClean = firstClean.withColumn('location', when(firstClean.location.like('%England%'), 'England').otherwise(firstClean['location']))\n",
    "#firstClean = firstClean.withColumn('location', when(firstClean.location.like('%Wales%'), 'Wales').otherwise(firstClean['location']))\n",
    "#firstClean = firstClean.withColumn('location', when(firstClean.location.like('%Scotland%'), 'Scotland').otherwise(firstClean['location']))\n",
    "#firstClean = firstClean.withColumn('location', when(firstClean.location.like('%Northern Ireland%'), 'NI').otherwise(firstClean['location']))\n",
    "#firstClean = firstClean.withColumn('location', when(firstClean.location.like('%NI%'), 'NI').otherwise(firstClean['location']))\n",
    "#firstClean = firstClean.withColumn('location', when(firstClean.location.like('%UK%'), 'UK').otherwise(firstClean['location']))\n",
    "#firstClean = firstClean.withColumn('location', when(firstClean.location.like('%uk%'), 'UK').otherwise(firstClean['location']))\n",
    "\n",
    "firstClean.agg(count(\"location\")).show()\n",
    "firstClean.agg(countDistinct(\"location\")).show()\n",
    "firstClean.groupBy(\"location\").count().sort(col(\"count\").desc()).show(100, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "firstClean = firstClean.withColumn('location', regexp_replace('location', 'Nottingham', 'England'))\n",
    "firstClean = firstClean.withColumn('location', regexp_replace('location', 'manchester', 'England'))\n",
    "firstClean = firstClean.withColumn('location', regexp_replace('location', 'Wakefield', 'England'))\n",
    "firstClean = firstClean.withColumn('location', regexp_replace('location', 'Hull', 'England'))\n",
    "firstClean = firstClean.withColumn('location', regexp_replace('location', 'York', 'England'))\n",
    "firstClean = firstClean.withColumn('location', regexp_replace('location', 'Shropshire', 'England'))\n",
    "firstClean = firstClean.withColumn('location', regexp_replace('location', 'Long Compton, South Warks', 'England'))\n",
    "firstClean = firstClean.withColumn('location', regexp_replace('location', 'Cumbria', 'England'))\n",
    "firstClean = firstClean.withColumn('location', regexp_replace('location', 'Devon', 'England'))\n",
    "firstClean = firstClean.withColumn('location', regexp_replace('location', 'Newcastle upon Tyne', 'England'))\n",
    "firstClean = firstClean.withColumn('location', regexp_replace('location', 'Hastings', 'England'))\n",
    "firstClean = firstClean.withColumn('location', regexp_replace('location', 'hull', 'England'))\n",
    "firstClean = firstClean.withColumn('location', regexp_replace('location', 'wigan', 'England'))\n",
    "firstClean = firstClean.withColumn('location', when(firstClean.location.like('%england%'), 'England').otherwise(firstClean['location']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------+\n",
      "|count(location)|\n",
      "+---------------+\n",
      "|          10780|\n",
      "+---------------+\n",
      "\n",
      "+------------------------+\n",
      "|count(DISTINCT location)|\n",
      "+------------------------+\n",
      "|                    3167|\n",
      "+------------------------+\n",
      "\n",
      "+------------------------------+-----+\n",
      "|location                      |count|\n",
      "+------------------------------+-----+\n",
      "|England                       |4489 |\n",
      "|UK                            |1034 |\n",
      "|Scotland                      |501  |\n",
      "|Wales                         |245  |\n",
      "|NI                            |77   |\n",
      "|People's Republic of China    |8    |\n",
      "|Dorset                        |7    |\n",
      "|Whitstable                    |7    |\n",
      "|America                       |7    |\n",
      "|Michigan                      |7    |\n",
      "|The Netherlands               |7    |\n",
      "| Dorset, Ireland, Spain       |7    |\n",
      "|Paris                         |7    |\n",
      "|Up North                      |7    |\n",
      "|Florida                       |7    |\n",
      "|South Carolina                |7    |\n",
      "|Melbourne, Victoria           |7    |\n",
      "|Lagos, Nigeria                |7    |\n",
      "|Tx                            |7    |\n",
      "|The outer reaches.            |6    |\n",
      "|University of Stirling        |6    |\n",
      "|Tennessee                     |6    |\n",
      "|Cheshire                      |6    |\n",
      "|Japan                         |6    |\n",
      "|Connecticut                   |6    |\n",
      "|Newport, Isle of Wight        |6    |\n",
      "|Columbus, OH                  |6    |\n",
      "|citizen of the world          |6    |\n",
      "|Citizen of Nowhere            |6    |\n",
      "|Basingstoke                   |6    |\n",
      "|Virginia                      |6    |\n",
      "|Uk                            |6    |\n",
      "|Southampton                   |6    |\n",
      "|Oslo, Norway                  |6    |\n",
      "|Abuja, Nigeria                |6    |\n",
      "|Bournemouth                   |6    |\n",
      "|Here                          |6    |\n",
      "|Suffolk                       |6    |\n",
      "|San Francisco                 |6    |\n",
      "|Inverness                     |6    |\n",
      "|Epsom, South East             |6    |\n",
      "|English Midlands              |6    |\n",
      "|Worcestershire                |6    |\n",
      "|he/him                        |6    |\n",
      "|Florence, Tuscany             |6    |\n",
      "|Russia                        |6    |\n",
      "|Berkshire                     |6    |\n",
      "|Cork, Ireland                 |5    |\n",
      "|LDN                           |5    |\n",
      "|South                         |5    |\n",
      "|Aberdeenshire                 |5    |\n",
      "|America                       |5    |\n",
      "|North America                 |5    |\n",
      "|glasgow                       |5    |\n",
      "|united kingdom                |5    |\n",
      "|nowhere man.                  |5    |\n",
      "|Podunkville                   |5    |\n",
      "|Universe                      |5    |\n",
      "|Spain                         |5    |\n",
      "|not in a vote remain area     |5    |\n",
      "|chesterfield                  |5    |\n",
      "|Missouri                      |5    |\n",
      "|Brideshead                    |5    |\n",
      "|Galway, Ireland               |5    |\n",
      "|Coningsby, Lincs              |5    |\n",
      "|Reading                       |5    |\n",
      "|She/her                       |5    |\n",
      "|Nigeria                       |5    |\n",
      "|Prague, Czech Republic        |5    |\n",
      "|Portsmouth                    |5    |\n",
      "|Home                          |5    |\n",
      "|Andalusia, Spain              |5    |\n",
      "|Croydon                       |5    |\n",
      "|Northumberland                |5    |\n",
      "|The World                     |5    |\n",
      "|Herefordshire                 |5    |\n",
      "|Finsbury Park                 |5    |\n",
      "|Wirral                        |5    |\n",
      "|Moscow,Russia                 |5    |\n",
      "|Staffordshire                 |5    |\n",
      "|Croydon                       |5    |\n",
      "|Vancouver, BC                 |4    |\n",
      "|Pali Hill                     |4    |\n",
      "|Mother Box                    |4    |\n",
      "|Taunton Somerset              |4    |\n",
      "|Minneapolis, MN               |4    |\n",
      "|Espa√±a                        |4    |\n",
      "|Calgary, Alberta              |4    |\n",
      "|Avalon                        |4    |\n",
      "|Gibraltar                     |4    |\n",
      "|North West                    |4    |\n",
      "|southampton                   |4    |\n",
      "|Nowhere                       |4    |\n",
      "|tampa bay                     |4    |\n",
      "|Exeter                        |4    |\n",
      "|Ontario                       |4    |\n",
      "|Atlanta                       |4    |\n",
      "|Oregon                        |4    |\n",
      "|NEW JERSEY                    |4    |\n",
      "|the bad place aka tory britain|4    |\n",
      "+------------------------------+-----+\n",
      "only showing top 100 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "firstClean.agg(count(\"location\")).show()\n",
    "firstClean.agg(countDistinct(\"location\")).show()\n",
    "firstClean.groupBy(\"location\").count().sort(col(\"count\").desc()).show(100, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "firstClean = firstClean.withColumn('location', regexp_replace('location', 'Whitestable', 'England'))\n",
    "firstClean = firstClean.withColumn('location', regexp_replace('location', 'Dorest', 'England'))\n",
    "firstClean = firstClean.withColumn('location', regexp_replace('location', 'Cheshire', 'England'))\n",
    "firstClean = firstClean.withColumn('location', regexp_replace('location', 'Isle of Wight', 'England'))\n",
    "firstClean = firstClean.withColumn('location', regexp_replace('location', 'Southampton', 'England'))\n",
    "firstClean = firstClean.withColumn('location', regexp_replace('location', 'Suffolk', 'England'))\n",
    "firstClean = firstClean.withColumn('location', regexp_replace('location', 'Basingstoke, South Warks', 'England'))\n",
    "firstClean = firstClean.withColumn('location', regexp_replace('location', 'Bournemouth', 'England'))\n",
    "firstClean = firstClean.withColumn('location', regexp_replace('location', 'Epsom', 'England'))\n",
    "firstClean = firstClean.withColumn('location', regexp_replace('location', 'Worcestershire', 'England'))\n",
    "firstClean = firstClean.withColumn('location', regexp_replace('location', 'English', 'England'))\n",
    "firstClean = firstClean.withColumn('location', regexp_replace('location', 'Aberdeenshire', 'Scotland'))\n",
    "firstClean = firstClean.withColumn('location', regexp_replace('location', 'glasgow', 'Scotland'))\n",
    "firstClean = firstClean.withColumn('location', when(firstClean.location.like('%England%'), 'England').otherwise(firstClean['location']))\n",
    "firstClean = firstClean.withColumn('location', when(firstClean.location.like('%Uk%'), 'UK').otherwise(firstClean['location']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------+-------------+--------+-----------+----------+-------------------+--------------------------------------------------------------------------------------------------------------------------------------------+-------------------+\n",
      "|followers_count|friends_count|hashtags|is_verified|location  |reply_count        |text                                                                                                                                        |userId             |\n",
      "+---------------+-------------+--------+-----------+----------+-------------------+--------------------------------------------------------------------------------------------------------------------------------------------+-------------------+\n",
      "|2387           |4996         |[]      |false      |England   |1205470817959776257|Urgh                                                                                                                                        |351883595          |\n",
      "|326            |403          |[]      |false      |England   |1205399777216802817|@KentishJane Here's mine from earlier:\n",
      "\n",
      "https://t.co/pxkPHSZ0k0                                                                             |744537718043086849 |\n",
      "|3613           |2396         |[]      |false      |England   |1205421989189566465|RT @mrjamesob: Here we go... https://t.co/9LMS3lkhJv                                                                                        |112500296          |\n",
      "|182            |533          |[]      |false      |somewhere |1205249028637806592|Most of this. https://t.co/wphg1rTe05\n",
      "\n",
      "Every single word of thisüëá                                                                          |47301219           |\n",
      "|2221           |4477         |[]      |false      |England   |1205477350143594497|RT @richarddflowers: Liberalism continues to renew itself, with new voices to carry on the fight - and we are going to need Liberal voices‚Ä¶ |1185604978964127756|\n",
      "|252            |1128         |[]      |false      |they/them |1205378194334978049|RT @pencilbandit: An annual reminder that both our non-proportional voting system and split left vote are utter trash garbage:\n",
      "\n",
      "14.4M for T‚Ä¶|1050801301855064064|\n",
      "|750            |663          |[]      |false      |Off campus|1205368801438707713|RT @grumpwitch: [long, watery fart sounds followed by violent gagging] https://t.co/CvwWeSY1Al                                              |2211160426         |\n",
      "|493            |2061         |[]      |false      |UK        |1205475508949078016|RT @theobertram: John Curtice: ‚ÄúLabour's vote fell on average by more than 10 points in the most pro-Leave areas and by more than six point‚Ä¶|57025876           |\n",
      "|2832           |785          |[]      |false      |UK        |1205266744002142208|Enjoy the day folks... bathe in their misery... :)                                                                                          |106469050          |\n",
      "|1808           |1341         |[]      |false      |England   |1205441159805444098|RT @BathCA: Gosh. The big Guy himself.\n",
      "Are Wera, @LordStras and @BathforEurope listening?\n",
      "\n",
      "@StephenSumner15 \n",
      "@BBCBristol \n",
      "@AliRVowles https‚Ä¶|3511592775         |\n",
      "+---------------+-------------+--------+-----------+----------+-------------------+--------------------------------------------------------------------------------------------------------------------------------------------+-------------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "firstClean.show(10, False)\n",
    "#firstClean.agg(count(\"location\")).show()\n",
    "#firstClean.agg(countDistinct(\"location\")).show()\n",
    "#firstClean.groupBy(\"location\").count().sort(col(\"count\").desc()).show(100, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "firstClean = firstClean.withColumn('location', regexp_replace('location', 'Cheshire', 'England'))\n",
    "firstClean = firstClean.withColumn('location', regexp_replace('location', 'Isle of Wight', 'England'))\n",
    "firstClean = firstClean.withColumn('location', regexp_replace('location', 'Southampton', 'England'))\n",
    "firstClean = firstClean.withColumn('location', regexp_replace('location', 'Suffolk', 'England'))\n",
    "firstClean = firstClean.withColumn('location', regexp_replace('location', 'Basingstoke, South Warks', 'England'))\n",
    "firstClean = firstClean.withColumn('location', regexp_replace('location', 'Bournemouth', 'England'))\n",
    "firstClean = firstClean.withColumn('location', regexp_replace('location', 'Epsom', 'England'))\n",
    "firstClean = firstClean.withColumn('location', regexp_replace('location', 'Worcestershire', 'England'))\n",
    "firstClean = firstClean.withColumn('location', regexp_replace('location', 'English', 'England'))\n",
    "firstClean = firstClean.withColumn('location', regexp_replace('location', 'Aberdeenshire', 'Scotland'))\n",
    "firstClean = firstClean.withColumn('location', regexp_replace('location', 'glasgow', 'Scotland'))\n",
    "firstClean = firstClean.withColumn('location', when(firstClean.location.like('%England%'), 'England').otherwise(firstClean['location']))\n",
    "firstClean = firstClean.withColumn('location', when(firstClean.location.like('%Uk%'), 'UK').otherwise(firstClean['location']))\n",
    "firstClean.coalesce(1).write.json(\"file:///Users/Laith/Downloads/features_tweets2.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- followers_count: long (nullable = true)\n",
      " |-- friends_count: long (nullable = true)\n",
      " |-- hashtags: array (nullable = true)\n",
      " |    |-- element: struct (containsNull = true)\n",
      " |    |    |-- indices: array (nullable = true)\n",
      " |    |    |    |-- element: long (containsNull = true)\n",
      " |    |    |-- text: string (nullable = true)\n",
      " |-- is_verified: boolean (nullable = true)\n",
      " |-- location: string (nullable = true)\n",
      " |-- reply_count: long (nullable = true)\n",
      " |-- text: string (nullable = true)\n",
      " |-- userId: long (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Load secondClean tweets \n",
    "secondClean = spark.read.json(\"file:///Users/Laith/Downloads/secondClean.json\")\n",
    "\n",
    "#Print the schema/data structure in a tree format\n",
    "secondClean.printSchema()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------+\n",
      "|count(location)|\n",
      "+---------------+\n",
      "|          10780|\n",
      "+---------------+\n",
      "\n",
      "+------------------------+\n",
      "|count(DISTINCT location)|\n",
      "+------------------------+\n",
      "|                    3095|\n",
      "+------------------------+\n",
      "\n",
      "+------------------------------+-----+\n",
      "|location                      |count|\n",
      "+------------------------------+-----+\n",
      "|England                       |4617 |\n",
      "|UK                            |1047 |\n",
      "|Scotland                      |511  |\n",
      "|Wales                         |245  |\n",
      "|NI                            |77   |\n",
      "|People's Republic of China    |8    |\n",
      "|Florida                       |7    |\n",
      "|Whitstable                    |7    |\n",
      "|Michigan                      |7    |\n",
      "| Dorset, Ireland, Spain       |7    |\n",
      "|Up North                      |7    |\n",
      "|America                       |7    |\n",
      "|The Netherlands               |7    |\n",
      "|Paris                         |7    |\n",
      "|Melbourne, Victoria           |7    |\n",
      "|South Carolina                |7    |\n",
      "|Dorset                        |7    |\n",
      "|Lagos, Nigeria                |7    |\n",
      "|Tx                            |7    |\n",
      "|Russia                        |6    |\n",
      "|Japan                         |6    |\n",
      "|San Francisco                 |6    |\n",
      "|The outer reaches.            |6    |\n",
      "|Basingstoke                   |6    |\n",
      "|citizen of the world          |6    |\n",
      "|University of Stirling        |6    |\n",
      "|Virginia                      |6    |\n",
      "|Here                          |6    |\n",
      "|Oslo, Norway                  |6    |\n",
      "|Abuja, Nigeria                |6    |\n",
      "|Tennessee                     |6    |\n",
      "|Inverness                     |6    |\n",
      "|he/him                        |6    |\n",
      "|Florence, Tuscany             |6    |\n",
      "|Connecticut                   |6    |\n",
      "|Citizen of Nowhere            |6    |\n",
      "|Columbus, OH                  |6    |\n",
      "|Berkshire                     |6    |\n",
      "|Universe                      |5    |\n",
      "|united kingdom                |5    |\n",
      "|Nigeria                       |5    |\n",
      "|South                         |5    |\n",
      "|North America                 |5    |\n",
      "|Portsmouth                    |5    |\n",
      "|Spain                         |5    |\n",
      "|LDN                           |5    |\n",
      "|chesterfield                  |5    |\n",
      "|not in a vote remain area     |5    |\n",
      "|Northumberland                |5    |\n",
      "|Coningsby, Lincs              |5    |\n",
      "|Cork, Ireland                 |5    |\n",
      "|Galway, Ireland               |5    |\n",
      "|Reading                       |5    |\n",
      "|Podunkville                   |5    |\n",
      "|Prague, Czech Republic        |5    |\n",
      "|Staffordshire                 |5    |\n",
      "|America                       |5    |\n",
      "|Andalusia, Spain              |5    |\n",
      "|Home                          |5    |\n",
      "|Herefordshire                 |5    |\n",
      "|Missouri                      |5    |\n",
      "|The World                     |5    |\n",
      "|Croydon                       |5    |\n",
      "|Brideshead                    |5    |\n",
      "|Moscow,Russia                 |5    |\n",
      "|Wirral                        |5    |\n",
      "|nowhere man.                  |5    |\n",
      "|Croydon                       |5    |\n",
      "|Finsbury Park                 |5    |\n",
      "|She/her                       |5    |\n",
      "|Asturias, de momento          |4    |\n",
      "|Italia                        |4    |\n",
      "|South West                    |4    |\n",
      "|Within the sound of Bow Bells |4    |\n",
      "|Gibraltar                     |4    |\n",
      "|The Moon                      |4    |\n",
      "|Somerset                      |4    |\n",
      "|Al lado del Cagay√°n de Oro    |4    |\n",
      "|Oregon                        |4    |\n",
      "|Pembrokeshire                 |4    |\n",
      "|Kriopigi, Kassandra, Greece   |4    |\n",
      "|Tarheel State                 |4    |\n",
      "|southampton                   |4    |\n",
      "|Nowhere                       |4    |\n",
      "|Avalon                        |4    |\n",
      "|the bad place aka tory britain|4    |\n",
      "|Minneapolis, MN               |4    |\n",
      "|Swindon                       |4    |\n",
      "|Wokingham                     |4    |\n",
      "|Pali Hill                     |4    |\n",
      "|Vancouver, BC                 |4    |\n",
      "|Espa√±a                        |4    |\n",
      "|Ontario                       |4    |\n",
      "|Moscow, Russia                |4    |\n",
      "|tampa bay                     |4    |\n",
      "|Lagos                         |4    |\n",
      "|Exeter                        |4    |\n",
      "|North West                    |4    |\n",
      "|everywhere                    |4    |\n",
      "|NEW JERSEY                    |4    |\n",
      "+------------------------------+-----+\n",
      "only showing top 100 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "secondClean.agg(count(\"location\")).show()\n",
    "secondClean.agg(countDistinct(\"location\")).show()\n",
    "secondClean.groupBy(\"location\").count().sort(col(\"count\").desc()).show(100, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "secondClean = secondClean.withColumn('location', regexp_replace('location', 'Whitstable', 'England'))\n",
    "secondClean = secondClean.withColumn('location', regexp_replace('location', 'Dorset', 'England'))\n",
    "secondClean = secondClean.withColumn('location', regexp_replace('location', 'Inverness', 'Scotland'))\n",
    "secondClean = secondClean.withColumn('location', regexp_replace('location', 'Berkshire', 'England'))\n",
    "secondClean = secondClean.withColumn('location', regexp_replace('location', 'Basingstoke', 'England'))\n",
    "secondClean = secondClean.withColumn('location', regexp_replace('location', 'Wirral', 'England'))\n",
    "secondClean = secondClean.withColumn('location', regexp_replace('location', 'Croydon', 'England'))\n",
    "secondClean = secondClean.withColumn('location', regexp_replace('location', 'Northumberland', 'England'))\n",
    "secondClean = secondClean.withColumn('location', regexp_replace('location', 'Coningsby', 'England'))\n",
    "secondClean = secondClean.withColumn('location', regexp_replace('location', 'Finsbury', 'England'))\n",
    "secondClean = secondClean.withColumn('location', regexp_replace('location', 'Herefordshire', 'England'))\n",
    "secondClean = secondClean.withColumn('location', regexp_replace('location', 'Taunton', 'England'))\n",
    "secondClean = secondClean.withColumn('location', regexp_replace('location', 'southampton', 'England'))\n",
    "secondClean = secondClean.withColumn('location', regexp_replace('location', 'Swindon', 'England'))\n",
    "secondClean = secondClean.withColumn('location', regexp_replace('location', 'Pembrokeshire', 'England'))\n",
    "secondClean = secondClean.withColumn('location', regexp_replace('location', 'Gibraltar', 'UK'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------+\n",
      "|count(location)|\n",
      "+---------------+\n",
      "|          10780|\n",
      "+---------------+\n",
      "\n",
      "+------------------------+\n",
      "|count(DISTINCT location)|\n",
      "+------------------------+\n",
      "|                    3081|\n",
      "+------------------------+\n",
      "\n",
      "+-----------------------------+-----+\n",
      "|location                     |count|\n",
      "+-----------------------------+-----+\n",
      "|England                      |4675 |\n",
      "|UK                           |1051 |\n",
      "|Scotland                     |517  |\n",
      "|Wales                        |245  |\n",
      "|NI                           |77   |\n",
      "|People's Republic of China   |8    |\n",
      "|Florida                      |7    |\n",
      "|Michigan                     |7    |\n",
      "|Up North                     |7    |\n",
      "|Paris                        |7    |\n",
      "|America                      |7    |\n",
      "|The Netherlands              |7    |\n",
      "|South Carolina               |7    |\n",
      "|Tx                           |7    |\n",
      "|Lagos, Nigeria               |7    |\n",
      "| England, Ireland, Spain     |7    |\n",
      "|Melbourne, Victoria          |7    |\n",
      "|Here                         |6    |\n",
      "|Tennessee                    |6    |\n",
      "|The outer reaches.           |6    |\n",
      "|citizen of the world         |6    |\n",
      "|Virginia                     |6    |\n",
      "|Oslo, Norway                 |6    |\n",
      "|Japan                        |6    |\n",
      "|University of Stirling       |6    |\n",
      "|Abuja, Nigeria               |6    |\n",
      "|he/him                       |6    |\n",
      "|San Francisco                |6    |\n",
      "|Citizen of Nowhere           |6    |\n",
      "|Florence, Tuscany            |6    |\n",
      "|Russia                       |6    |\n",
      "|Connecticut                  |6    |\n",
      "|England                      |6    |\n",
      "|Columbus, OH                 |6    |\n",
      "|Universe                     |5    |\n",
      "|not in a vote remain area    |5    |\n",
      "|Staffordshire                |5    |\n",
      "|Nigeria                      |5    |\n",
      "|America                      |5    |\n",
      "|North America                |5    |\n",
      "|Brideshead                   |5    |\n",
      "|Moscow,Russia                |5    |\n",
      "|Podunkville                  |5    |\n",
      "|Portsmouth                   |5    |\n",
      "|nowhere man.                 |5    |\n",
      "|Andalusia, Spain             |5    |\n",
      "|LDN                          |5    |\n",
      "|South                        |5    |\n",
      "|Galway, Ireland              |5    |\n",
      "|Cork, Ireland                |5    |\n",
      "|She/her                      |5    |\n",
      "|Reading                      |5    |\n",
      "|united kingdom               |5    |\n",
      "|Prague, Czech Republic       |5    |\n",
      "|Home                         |5    |\n",
      "|chesterfield                 |5    |\n",
      "|England, Lincs               |5    |\n",
      "|Spain                        |5    |\n",
      "|England Park                 |5    |\n",
      "|The World                    |5    |\n",
      "|Missouri                     |5    |\n",
      "|Plymouth                     |4    |\n",
      "|NEW JERSEY                   |4    |\n",
      "|Luton,BPYP Notorious.        |4    |\n",
      "|Brentwood, East              |4    |\n",
      "|Pennsylvania                 |4    |\n",
      "|South West                   |4    |\n",
      "|Kildare, Ireland             |4    |\n",
      "|Wokingham                    |4    |\n",
      "|Moscow, Russia               |4    |\n",
      "|Ontario                      |4    |\n",
      "|Kriopigi, Kassandra, Greece  |4    |\n",
      "|south wales                  |4    |\n",
      "|Gloucestershire              |4    |\n",
      "|Vancouver, BC                |4    |\n",
      "|Somerset                     |4    |\n",
      "|Pali Hill                    |4    |\n",
      "|Mother Box                   |4    |\n",
      "|Al lado del Cagay√°n de Oro   |4    |\n",
      "|Minneapolis, MN              |4    |\n",
      "|Exeter                       |4    |\n",
      "|Once great BRITAIN           |4    |\n",
      "|Cambridgeshire               |4    |\n",
      "|Italia                       |4    |\n",
      "|Tarheel State                |4    |\n",
      "|Bangladesh                   |4    |\n",
      "|everywhere                   |4    |\n",
      "|Calgary, Alberta             |4    |\n",
      "|World                        |4    |\n",
      "|Espa√±a                       |4    |\n",
      "|England Somerset             |4    |\n",
      "|Atlanta                      |4    |\n",
      "|The Moon                     |4    |\n",
      "|tampa bay                    |4    |\n",
      "|Oregon                       |4    |\n",
      "|North West                   |4    |\n",
      "|St. Albans, Herts.           |4    |\n",
      "|Within the sound of Bow Bells|4    |\n",
      "|Sunderland                   |4    |\n",
      "|Nowhere                      |4    |\n",
      "+-----------------------------+-----+\n",
      "only showing top 100 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "secondClean.agg(count(\"location\")).show()\n",
    "secondClean.agg(countDistinct(\"location\")).show()\n",
    "secondClean.groupBy(\"location\").count().sort(col(\"count\").desc()).show(100, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------+\n",
      "|count(location)|\n",
      "+---------------+\n",
      "|          10780|\n",
      "+---------------+\n",
      "\n",
      "+------------------------+\n",
      "|count(DISTINCT location)|\n",
      "+------------------------+\n",
      "|                    3056|\n",
      "+------------------------+\n",
      "\n",
      "+------------------------------+-----+\n",
      "|location                      |count|\n",
      "+------------------------------+-----+\n",
      "|England                       |4721 |\n",
      "|UK                            |1056 |\n",
      "|Scotland                      |517  |\n",
      "|Wales                         |252  |\n",
      "|NI                            |77   |\n",
      "|People's Republic of China    |8    |\n",
      "|Florida                       |7    |\n",
      "|Up North                      |7    |\n",
      "|America                       |7    |\n",
      "|South Carolina                |7    |\n",
      "|Melbourne, Victoria           |7    |\n",
      "|The Netherlands               |7    |\n",
      "|Paris                         |7    |\n",
      "|Lagos, Nigeria                |7    |\n",
      "|Tx                            |7    |\n",
      "|Michigan                      |7    |\n",
      "|Russia                        |6    |\n",
      "|Tennessee                     |6    |\n",
      "|University of Stirling        |6    |\n",
      "|Oslo, Norway                  |6    |\n",
      "|citizen of the world          |6    |\n",
      "|Here                          |6    |\n",
      "|Japan                         |6    |\n",
      "|he/him                        |6    |\n",
      "|Abuja, Nigeria                |6    |\n",
      "|Florence, Tuscany             |6    |\n",
      "|Connecticut                   |6    |\n",
      "|San Francisco                 |6    |\n",
      "|Columbus, OH                  |6    |\n",
      "|Citizen of Nowhere            |6    |\n",
      "|Virginia                      |6    |\n",
      "|The outer reaches.            |6    |\n",
      "|South                         |5    |\n",
      "|Universe                      |5    |\n",
      "|not in a vote remain area     |5    |\n",
      "|Andalusia, Spain              |5    |\n",
      "|Cork, Ireland                 |5    |\n",
      "|nowhere man.                  |5    |\n",
      "|LDN                           |5    |\n",
      "|Staffordshire                 |5    |\n",
      "|The World                     |5    |\n",
      "|Moscow,Russia                 |5    |\n",
      "|Brideshead                    |5    |\n",
      "|Reading                       |5    |\n",
      "|She/her                       |5    |\n",
      "|Podunkville                   |5    |\n",
      "|North America                 |5    |\n",
      "|Prague, Czech Republic        |5    |\n",
      "|Spain                         |5    |\n",
      "|America                       |5    |\n",
      "|Nigeria                       |5    |\n",
      "|chesterfield                  |5    |\n",
      "|Missouri                      |5    |\n",
      "|Home                          |5    |\n",
      "|Portsmouth                    |5    |\n",
      "|Galway, Ireland               |5    |\n",
      "|Bangladesh                    |4    |\n",
      "|Ohio                          |4    |\n",
      "|Cambridgeshire                |4    |\n",
      "|Blackburn                     |4    |\n",
      "|Ontario                       |4    |\n",
      "|Kriopigi, Kassandra, Greece   |4    |\n",
      "|Cape Town, South Africa       |4    |\n",
      "|Asturias, de momento          |4    |\n",
      "|Tarheel State                 |4    |\n",
      "|Al lado del Cagay√°n de Oro    |4    |\n",
      "|Moscow, Russia                |4    |\n",
      "|Oregon                        |4    |\n",
      "|Altoona,WI                    |4    |\n",
      "|Kildare, Ireland              |4    |\n",
      "|Atlanta, GA                   |4    |\n",
      "|Sunderland                    |4    |\n",
      "|Brentwood, East               |4    |\n",
      "|everywhere                    |4    |\n",
      "|Avalon                        |4    |\n",
      "|The Moon                      |4    |\n",
      "|South West                    |4    |\n",
      "|tampa bay                     |4    |\n",
      "|Luton,BPYP Notorious.         |4    |\n",
      "|RuralPerthshire               |4    |\n",
      "|Gloucestershire               |4    |\n",
      "|Space                         |4    |\n",
      "|Milano, Lombardia             |4    |\n",
      "|Espa√±a                        |4    |\n",
      "|Somerset                      |4    |\n",
      "|Italia                        |4    |\n",
      "|Pennsylvania                  |4    |\n",
      "|Pali Hill                     |4    |\n",
      "|Lagos                         |4    |\n",
      "|Atlanta                       |4    |\n",
      "|the bad place aka tory britain|4    |\n",
      "|Once great BRITAIN            |4    |\n",
      "|Exeter                        |4    |\n",
      "|Elephant & Castle             |4    |\n",
      "|St. Albans, Herts.            |4    |\n",
      "|North West                    |4    |\n",
      "|Vancouver, BC                 |4    |\n",
      "|Wokingham                     |4    |\n",
      "|Within the sound of Bow Bells |4    |\n",
      "|NEW JERSEY                    |4    |\n",
      "+------------------------------+-----+\n",
      "only showing top 100 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "secondClean = secondClean.withColumn('location', when(secondClean.location.like('%England%'), 'England').otherwise(secondClean['location']))\n",
    "secondClean = secondClean.withColumn('location', when(secondClean.location.like('%united kingdom%'), 'UK').otherwise(secondClean['location']))\n",
    "secondClean = secondClean.withColumn('location', when(secondClean.location.like('%wales%'), 'Wales').otherwise(secondClean['location']))\n",
    "\n",
    "secondClean.agg(count(\"location\")).show()\n",
    "secondClean.agg(countDistinct(\"location\")).show()\n",
    "secondClean.groupBy(\"location\").count().sort(col(\"count\").desc()).show(100, False)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "secondClean.coalesce(1).write.json(\"file:///Users/Laith/Downloads/features_tweets3.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- followers_count: long (nullable = true)\n",
      " |-- friends_count: long (nullable = true)\n",
      " |-- hashtags: array (nullable = true)\n",
      " |    |-- element: struct (containsNull = true)\n",
      " |    |    |-- indices: array (nullable = true)\n",
      " |    |    |    |-- element: long (containsNull = true)\n",
      " |    |    |-- text: string (nullable = true)\n",
      " |-- is_verified: boolean (nullable = true)\n",
      " |-- location: string (nullable = true)\n",
      " |-- reply_count: long (nullable = true)\n",
      " |-- text: string (nullable = true)\n",
      " |-- userId: long (nullable = true)\n",
      "\n",
      "+---------------+\n",
      "|count(location)|\n",
      "+---------------+\n",
      "|          10780|\n",
      "+---------------+\n",
      "\n",
      "+------------------------+\n",
      "|count(DISTINCT location)|\n",
      "+------------------------+\n",
      "|                    3056|\n",
      "+------------------------+\n",
      "\n",
      "+------------------------------+-----+\n",
      "|location                      |count|\n",
      "+------------------------------+-----+\n",
      "|England                       |4721 |\n",
      "|UK                            |1056 |\n",
      "|Scotland                      |517  |\n",
      "|Wales                         |252  |\n",
      "|NI                            |77   |\n",
      "|People's Republic of China    |8    |\n",
      "|Up North                      |7    |\n",
      "|Paris                         |7    |\n",
      "|Florida                       |7    |\n",
      "|South Carolina                |7    |\n",
      "|The Netherlands               |7    |\n",
      "|Melbourne, Victoria           |7    |\n",
      "|Lagos, Nigeria                |7    |\n",
      "|Tx                            |7    |\n",
      "|America                       |7    |\n",
      "|Michigan                      |7    |\n",
      "|Russia                        |6    |\n",
      "|University of Stirling        |6    |\n",
      "|citizen of the world          |6    |\n",
      "|Tennessee                     |6    |\n",
      "|Here                          |6    |\n",
      "|Florence, Tuscany             |6    |\n",
      "|Japan                         |6    |\n",
      "|Abuja, Nigeria                |6    |\n",
      "|Oslo, Norway                  |6    |\n",
      "|he/him                        |6    |\n",
      "|San Francisco                 |6    |\n",
      "|Connecticut                   |6    |\n",
      "|Citizen of Nowhere            |6    |\n",
      "|Columbus, OH                  |6    |\n",
      "|Virginia                      |6    |\n",
      "|The outer reaches.            |6    |\n",
      "|Portsmouth                    |5    |\n",
      "|nowhere man.                  |5    |\n",
      "|Universe                      |5    |\n",
      "|North America                 |5    |\n",
      "|Moscow,Russia                 |5    |\n",
      "|Nigeria                       |5    |\n",
      "|Prague, Czech Republic        |5    |\n",
      "|Spain                         |5    |\n",
      "|not in a vote remain area     |5    |\n",
      "|America                       |5    |\n",
      "|Andalusia, Spain              |5    |\n",
      "|Cork, Ireland                 |5    |\n",
      "|Reading                       |5    |\n",
      "|Podunkville                   |5    |\n",
      "|Galway, Ireland               |5    |\n",
      "|She/her                       |5    |\n",
      "|LDN                           |5    |\n",
      "|South                         |5    |\n",
      "|Missouri                      |5    |\n",
      "|Staffordshire                 |5    |\n",
      "|Home                          |5    |\n",
      "|chesterfield                  |5    |\n",
      "|The World                     |5    |\n",
      "|Brideshead                    |5    |\n",
      "|Ohio                          |4    |\n",
      "|Wokingham                     |4    |\n",
      "|Cambridgeshire                |4    |\n",
      "|Brentwood, East               |4    |\n",
      "|Somerset                      |4    |\n",
      "|The Moon                      |4    |\n",
      "|Altoona,WI                    |4    |\n",
      "|Asturias, de momento          |4    |\n",
      "|Pali Hill                     |4    |\n",
      "|Avalon                        |4    |\n",
      "|Kriopigi, Kassandra, Greece   |4    |\n",
      "|Luton,BPYP Notorious.         |4    |\n",
      "|Gloucestershire               |4    |\n",
      "|St. Albans, Herts.            |4    |\n",
      "|Halifax, Nova Scotia          |4    |\n",
      "|Nowhere                       |4    |\n",
      "|Vancouver, BC                 |4    |\n",
      "|Calgary, Alberta              |4    |\n",
      "|Atlanta                       |4    |\n",
      "|Exeter                        |4    |\n",
      "|Oregon                        |4    |\n",
      "|Once great BRITAIN            |4    |\n",
      "|North West                    |4    |\n",
      "|RuralPerthshire               |4    |\n",
      "|Hampshire mostly              |4    |\n",
      "|Space                         |4    |\n",
      "|Tarheel State                 |4    |\n",
      "|World                         |4    |\n",
      "|Italia                        |4    |\n",
      "|Within the sound of Bow Bells |4    |\n",
      "|Espa√±a                        |4    |\n",
      "|everywhere                    |4    |\n",
      "|Moscow, Russia                |4    |\n",
      "|Mother Box                    |4    |\n",
      "|Minneapolis, MN               |4    |\n",
      "|the bad place aka tory britain|4    |\n",
      "|South West                    |4    |\n",
      "|tampa bay                     |4    |\n",
      "|Kildare, Ireland              |4    |\n",
      "|Elephant & Castle             |4    |\n",
      "|NEW JERSEY                    |4    |\n",
      "|Sunderland                    |4    |\n",
      "|Pennsylvania                  |4    |\n",
      "|Lagos                         |4    |\n",
      "+------------------------------+-----+\n",
      "only showing top 100 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Load secondClean tweets \n",
    "thirdClean = spark.read.json(\"file:///Users/Laith/Downloads/thirdClean.json\")\n",
    "\n",
    "#Print the schema/data structure in a tree format\n",
    "thirdClean.printSchema()\n",
    "\n",
    "thirdClean.agg(count(\"location\")).show()\n",
    "thirdClean.agg(countDistinct(\"location\")).show()\n",
    "thirdClean.groupBy(\"location\").count().sort(col(\"count\").desc()).show(100, False)\n",
    "\n",
    "thirdClean = thirdClean.withColumn('location', when(thirdClean.location.like('%Britain%'), 'UK').otherwise(thirdClean['location']))\n",
    "thirdClean = thirdClean.withColumn('location', when(thirdClean.location.like('%britain%'), 'UK').otherwise(thirdClean['location']))\n",
    "thirdClean = thirdClean.withColumn('location', when(thirdClean.location.like('%BRITAIN%'), 'UK').otherwise(thirdClean['location']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "thirdClean = thirdClean.withColumn('location', regexp_replace('location', 'Staffordshire', 'England'))\n",
    "thirdClean = thirdClean.withColumn('location', regexp_replace('location', 'Reading', 'England'))\n",
    "thirdClean = thirdClean.withColumn('location', regexp_replace('location', 'Portsmouth', 'England'))\n",
    "thirdClean = thirdClean.withColumn('location', regexp_replace('location', 'chesterfield', 'England'))\n",
    "thirdClean = thirdClean.withColumn('location', regexp_replace('location', 'Wokingham', 'England'))\n",
    "thirdClean = thirdClean.withColumn('location', regexp_replace('location', 'isle of wight', 'England'))\n",
    "thirdClean = thirdClean.withColumn('location', regexp_replace('location', 'Elephant & Castle', 'England'))\n",
    "thirdClean = thirdClean.withColumn('location', regexp_replace('location', 'Cambridgeshire', 'England'))\n",
    "thirdClean = thirdClean.withColumn('location', regexp_replace('location', 'Brentwood, East', 'England'))\n",
    "thirdClean = thirdClean.withColumn('location', regexp_replace('location', 'Sunderland', 'England'))\n",
    "thirdClean = thirdClean.withColumn('location', regexp_replace('location', 'newcastle upon tyne', 'England'))\n",
    "thirdClean = thirdClean.withColumn('location', regexp_replace('location', 'Exeter', 'England'))\n",
    "thirdClean = thirdClean.withColumn('location', regexp_replace('location', 'Hampshire mostly', 'England'))\n",
    "thirdClean = thirdClean.withColumn('location', regexp_replace('location', 'Gloucestershire', 'England'))\n",
    "thirdClean = thirdClean.withColumn('location', regexp_replace('location', 'Norfolk', 'England'))\n",
    "\n",
    "thirdClean = thirdClean.withColumn('location', when(thirdClean.location.like('%England%'), 'England').otherwise(thirdClean['location']))\n",
    "thirdClean = thirdClean.withColumn('location', when(thirdClean.location.like('%scotland%'), 'Scotland').otherwise(thirdClean['location']))\n",
    "thirdClean = thirdClean.withColumn('location', when(thirdClean.location.like('%Scotland%'), 'Scotland').otherwise(thirdClean['location']))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------+\n",
      "|count(location)|\n",
      "+---------------+\n",
      "|          10780|\n",
      "+---------------+\n",
      "\n",
      "+------------------------+\n",
      "|count(DISTINCT location)|\n",
      "+------------------------+\n",
      "|                    3004|\n",
      "+------------------------+\n",
      "\n",
      "+-----------------------------------------------------+-----+\n",
      "|location                                             |count|\n",
      "+-----------------------------------------------------+-----+\n",
      "|England                                              |4808 |\n",
      "|UK                                                   |1076 |\n",
      "|Scotland                                             |524  |\n",
      "|Wales                                                |252  |\n",
      "|NI                                                   |77   |\n",
      "|People's Republic of China                           |8    |\n",
      "|South Carolina                                       |7    |\n",
      "|Up North                                             |7    |\n",
      "|America                                              |7    |\n",
      "|Florida                                              |7    |\n",
      "|Melbourne, Victoria                                  |7    |\n",
      "|Paris                                                |7    |\n",
      "|Lagos, Nigeria                                       |7    |\n",
      "|The Netherlands                                      |7    |\n",
      "|Michigan                                             |7    |\n",
      "|Tx                                                   |7    |\n",
      "|Here                                                 |6    |\n",
      "|Citizen of Nowhere                                   |6    |\n",
      "|Japan                                                |6    |\n",
      "|Tennessee                                            |6    |\n",
      "|Columbus, OH                                         |6    |\n",
      "|he/him                                               |6    |\n",
      "|University of Stirling                               |6    |\n",
      "|citizen of the world                                 |6    |\n",
      "|Florence, Tuscany                                    |6    |\n",
      "|Oslo, Norway                                         |6    |\n",
      "|Virginia                                             |6    |\n",
      "|Abuja, Nigeria                                       |6    |\n",
      "|San Francisco                                        |6    |\n",
      "|Russia                                               |6    |\n",
      "|Connecticut                                          |6    |\n",
      "|The outer reaches.                                   |6    |\n",
      "|Moscow,Russia                                        |5    |\n",
      "|South                                                |5    |\n",
      "|Podunkville                                          |5    |\n",
      "|The World                                            |5    |\n",
      "|Universe                                             |5    |\n",
      "|Galway, Ireland                                      |5    |\n",
      "|not in a vote remain area                            |5    |\n",
      "|Home                                                 |5    |\n",
      "|Andalusia, Spain                                     |5    |\n",
      "|Nigeria                                              |5    |\n",
      "|LDN                                                  |5    |\n",
      "|Prague, Czech Republic                               |5    |\n",
      "|North America                                        |5    |\n",
      "|Spain                                                |5    |\n",
      "|Missouri                                             |5    |\n",
      "|She/her                                              |5    |\n",
      "|America                                              |5    |\n",
      "|nowhere man.                                         |5    |\n",
      "|Brideshead                                           |5    |\n",
      "|Cork, Ireland                                        |5    |\n",
      "|N E U K                                              |4    |\n",
      "|                                                     |4    |\n",
      "|Afterlife                                            |4    |\n",
      "|Denver, CO                                           |4    |\n",
      "|Nowhere                                              |4    |\n",
      "|Kildare, Ireland                                     |4    |\n",
      "|Altoona,WI                                           |4    |\n",
      "|St Louis, MO                                         |4    |\n",
      "|World                                                |4    |\n",
      "|Bern, Schweiz                                        |4    |\n",
      "|Hungary                                              |4    |\n",
      "|Sweden                                               |4    |\n",
      "|St Albans                                            |4    |\n",
      "|Espa√±a                                               |4    |\n",
      "|Plymouth                                             |4    |\n",
      "|Milano, Lombardia                                    |4    |\n",
      "|Bangladesh                                           |4    |\n",
      "|North West                                           |4    |\n",
      "|Minneapolis, MN                                      |4    |\n",
      "|Kriopigi, Kassandra, Greece                          |4    |\n",
      "|Within the sound of Bow Bells                        |4    |\n",
      "|Halifax, Nova Scotia                                 |4    |\n",
      "|Luton,BPYP Notorious.                                |4    |\n",
      "|Vancouver, BC                                        |4    |\n",
      "|RuralPerthshire                                      |4    |\n",
      "|Calgary, Alberta                                     |4    |\n",
      "|Al lado del Cagay√°n de Oro                           |4    |\n",
      "|Lagos                                                |4    |\n",
      "|Mother Box                                           |4    |\n",
      "|Moscow, Russia                                       |4    |\n",
      "|Space                                                |4    |\n",
      "|NEW JERSEY                                           |4    |\n",
      "|Cape Town, South Africa                              |4    |\n",
      "|Italia                                               |4    |\n",
      "|St. Albans, Herts.                                   |4    |\n",
      "|everywhere                                           |4    |\n",
      "|S√£o Paulo, Brasil                                    |4    |\n",
      "|here&there, but mostly here                          |4    |\n",
      "|Hertfordshire                                        |4    |\n",
      "|tampa bay                                            |4    |\n",
      "|Oregon                                               |4    |\n",
      "|cheshire                                             |4    |\n",
      "|Asturias, de momento                                 |4    |\n",
      "|Somerset                                             |4    |\n",
      "|Ohio                                                 |4    |\n",
      "|Atlanta                                              |4    |\n",
      "|Avalon                                               |4    |\n",
      "|Chennai                                              |4    |\n",
      "|Blackburn                                            |4    |\n",
      "|Ontario                                              |4    |\n",
      "|The Moon                                             |4    |\n",
      "|Atlanta, GA                                          |4    |\n",
      "|South West                                           |4    |\n",
      "|Pennsylvania                                         |4    |\n",
      "|Tarheel State                                        |4    |\n",
      "|Pali Hill                                            |4    |\n",
      "|Guildford, surrey.                                   |3    |\n",
      "|Newcastle-Gateshead                                  |3    |\n",
      "|Cotswolds                                            |3    |\n",
      "|NC                                                   |3    |\n",
      "|Amsterdam                                            |3    |\n",
      "|kent                                                 |3    |\n",
      "|Anglosphere                                          |3    |\n",
      "|Neath Neath Neath                                    |3    |\n",
      "|U.S.A.                                               |3    |\n",
      "|Winnipeg, Manitoba                                   |3    |\n",
      "|No Deal Best Deal                                    |3    |\n",
      "|Shadowbannia                                         |3    |\n",
      "|Limerick, Ireland                                    |3    |\n",
      "|Newcastle Upon Tyne                                  |3    |\n",
      "|Luxembourg                                           |3    |\n",
      "|Leicester                                            |3    |\n",
      "|Wiltshire                                            |3    |\n",
      "|Leicestershire                                       |3    |\n",
      "|Cambridge                                            |3    |\n",
      "|Ayr                                                  |3    |\n",
      "|Georgia                                              |3    |\n",
      "|ayrshire                                             |3    |\n",
      "|Barcelona, Spain                                     |3    |\n",
      "|01206                                                |3    |\n",
      "|Burlington, NC                                       |3    |\n",
      "|√úT: 51.429261,-0.059685                              |3    |\n",
      "|Bangalore                                            |3    |\n",
      "|Lahore, Pakistan                                     |3    |\n",
      "|String O‚Äô Beads                                      |3    |\n",
      "|...with me it's a full time job. Now behave yourself.|3    |\n",
      "|somewhere                                            |3    |\n",
      "|üåç                                                   |3    |\n",
      "|Stockholm                                            |3    |\n",
      "|essex                                                |3    |\n",
      "|Richmond, VA                                         |3    |\n",
      "|staffordshire                                        |3    |\n",
      "|TN                                                   |3    |\n",
      "|Madrid, Spain                                        |3    |\n",
      "|Ancient Greece... possibly,                          |3    |\n",
      "|Abergavenny                                          |3    |\n",
      "|Serrapetrona (MC), Marche                            |3    |\n",
      "|North Carolina                                       |3    |\n",
      "|Co Armagh                                            |3    |\n",
      "|√úT: 51.78742,-0.41457                                |3    |\n",
      "|The fatherland                                       |3    |\n",
      "|Merseyside                                           |3    |\n",
      "|EEA/EFTA                                             |3    |\n",
      "|they/them                                            |3    |\n",
      "|Aberystwyth                                          |3    |\n",
      "|Nairobi                                              |3    |\n",
      "|West Coast                                           |3    |\n",
      "|Here.In front of you.                                |3    |\n",
      "|West Midlands                                        |3    |\n",
      "|Yattendon                                            |3    |\n",
      "|Chester                                              |3    |\n",
      "|Nashville, TN                                        |3    |\n",
      "|The Fourth Estate                                    |3    |\n",
      "|The world                                            |3    |\n",
      "|Coventry                                             |3    |\n",
      "|Notts                                                |3    |\n",
      "|Wakanda                                              |3    |\n",
      "|Detroit, MI                                          |3    |\n",
      "|Ibadan, Nigeria                                      |3    |\n",
      "|Antarctica                                           |3    |\n",
      "|Oslo                                                 |3    |\n",
      "|Argyll and Northamptonshire                          |3    |\n",
      "|üèîHighRockyNews RT for planet)                       |3    |\n",
      "|Hanging out with Devin‚Äôs üêÆ                          |3    |\n",
      "|Istanbul, Turkey                                     |3    |\n",
      "|Cambridge, MA                                        |3    |\n",
      "|#HS2                                                 |3    |\n",
      "|Cascadia                                             |3    |\n",
      "|Bharat                                               |3    |\n",
      "|yorkshire                                            |3    |\n",
      "|Minnesota                                            |3    |\n",
      "|Tulsa, OK                                            |3    |\n",
      "|Copenhagen, Denmark                                  |3    |\n",
      "|.                                                    |3    |\n",
      "|Masters of the World                                 |3    |\n",
      "|·Éö(‚ú°_‚ú°·Éö)                                              |3    |\n",
      "|160321 190430 190719 190720                          |3    |\n",
      "|DC                                                   |3    |\n",
      "|U.K.                                                 |3    |\n",
      "|liverpool                                            |3    |\n",
      "|Kendal                                               |3    |\n",
      "|Dyffryn Ardudwy                                      |3    |\n",
      "|florida                                              |3    |\n",
      "|Cleveland, OH                                        |3    |\n",
      "|Woking                                               |3    |\n",
      "|Brooklyn                                             |3    |\n",
      "|The Spice Islands                                    |3    |\n",
      "|Uranus                                               |3    |\n",
      "+-----------------------------------------------------+-----+\n",
      "only showing top 200 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "thirdClean.agg(count(\"location\")).show()\n",
    "thirdClean.agg(countDistinct(\"location\")).show()\n",
    "thirdClean.groupBy(\"location\").count().sort(col(\"count\").desc()).show(200, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "thirdClean.coalesce(1).write.json(\"file:///Users/Laith/Downloads/features_tweets4.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load secondClean tweets \n",
    "cleanData = spark.read.json(\"file:///Users/Laith/Downloads/fourthClean.json\")\n",
    "\n",
    "#Print the schema/data structure in a tree format\n",
    "#cleanData.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------+\n",
      "|count(location)|\n",
      "+---------------+\n",
      "|           6737|\n",
      "+---------------+\n",
      "\n",
      "+------------------------+\n",
      "|count(DISTINCT location)|\n",
      "+------------------------+\n",
      "|                       5|\n",
      "+------------------------+\n",
      "\n",
      "+--------+-----+\n",
      "|location|count|\n",
      "+--------+-----+\n",
      "| England| 4808|\n",
      "|      UK| 1076|\n",
      "|Scotland|  524|\n",
      "|   Wales|  252|\n",
      "|      NI|   77|\n",
      "+--------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "cleanData = cleanData.select(\"*\").where(\"location LIKE 'UK' OR location LIKE 'England' OR location LIKE 'NI' OR location LIKE 'Scotland' OR location LIKE 'Wales'\")\n",
    "cleanData.agg(count(\"location\")).show()\n",
    "cleanData.agg(countDistinct(\"location\")).show()\n",
    "cleanData.groupBy(\"location\").count().sort(col(\"count\").desc()).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- followers_count: long (nullable = true)\n",
      " |-- friends_count: long (nullable = true)\n",
      " |-- hashtags: array (nullable = true)\n",
      " |    |-- element: struct (containsNull = true)\n",
      " |    |    |-- indices: array (nullable = true)\n",
      " |    |    |    |-- element: long (containsNull = true)\n",
      " |    |    |-- text: string (nullable = true)\n",
      " |-- is_verified: boolean (nullable = true)\n",
      " |-- location: string (nullable = true)\n",
      " |-- reply_to: long (nullable = true)\n",
      " |-- text: string (nullable = true)\n",
      " |-- userId: long (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "cleanData = cleanData.withColumnRenamed('reply_count', 'reply_to')\n",
    "cleanData.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------Tokenizer--------------------------------\n",
      "+---------------+-------------+--------+-----------+--------+-------------------+---------------------------------------------------------------+------------------+---------------------------------------------------------------------+\n",
      "|followers_count|friends_count|hashtags|is_verified|location|reply_to           |text                                                           |userId            |words                                                                |\n",
      "+---------------+-------------+--------+-----------+--------+-------------------+---------------------------------------------------------------+------------------+---------------------------------------------------------------------+\n",
      "|2387           |4996         |[]      |false      |England |1205470817959776257|Urgh                                                           |351883595         |[urgh]                                                               |\n",
      "|326            |403          |[]      |false      |England |1205399777216802817|@KentishJane Here's mine from earlier:\n",
      "\n",
      "https://t.co/pxkPHSZ0k0|744537718043086849|[kentishjane, here, s, mine, from, earlier, https, t, co, pxkphsz0k0]|\n",
      "+---------------+-------------+--------+-----------+--------+-------------------+---------------------------------------------------------------+------------------+---------------------------------------------------------------------+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.feature import Tokenizer, RegexTokenizer\n",
    "from pyspark.sql.types import IntegerType\n",
    "from pyspark.ml.feature import StopWordsRemover\n",
    "print(\"---------------------Tokenizer--------------------------------\")\n",
    "#tokenizer = Tokenizer(inputCol=\"text\", outputCol=\"words\")\n",
    "regexTokenizer = RegexTokenizer(inputCol=\"text\", outputCol=\"words\", pattern=\"\\\\W\")\n",
    "countTokens = udf(lambda words: len(words), IntegerType())\n",
    "#tokenized = tokenizer.transform(tweetsDF)\n",
    "#tokenized.show(2, False)\n",
    "regexTokenized = regexTokenizer.transform(cleanData)\n",
    "regexTokenized.show(2, False)\n",
    "\n",
    "##I NEED ENOUGH MEMORY FOR THIS\n",
    "#regexTokenized.select(\"text\", \"words\").withColumn(\"tokens\", countTokens(col(\"words\"))).show(10, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------Stop Word Remover --------------------------------\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.feature import StopWordsRemover\n",
    "print(\"---------------------Stop Word Remover --------------------------------\")\n",
    "remover = StopWordsRemover(inputCol=\"words\", outputCol=\"filtered\")\n",
    "#remover.transform(tokenized).show(2, False)   \n",
    "cleanTweetsDF=remover.transform(regexTokenized) \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- followers_count: long (nullable = true)\n",
      " |-- friends_count: long (nullable = true)\n",
      " |-- hashtags: array (nullable = true)\n",
      " |    |-- element: struct (containsNull = true)\n",
      " |    |    |-- indices: array (nullable = true)\n",
      " |    |    |    |-- element: long (containsNull = true)\n",
      " |    |    |-- text: string (nullable = true)\n",
      " |-- is_verified: boolean (nullable = true)\n",
      " |-- location: string (nullable = true)\n",
      " |-- reply_to: long (nullable = true)\n",
      " |-- text: string (nullable = true)\n",
      " |-- userId: long (nullable = true)\n",
      " |-- words: array (nullable = true)\n",
      " |    |-- element: string (containsNull = true)\n",
      " |-- filtered: array (nullable = true)\n",
      " |    |-- element: string (containsNull = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "cleanTweetsDF.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- followers_count: long (nullable = true)\n",
      " |-- friends_count: long (nullable = true)\n",
      " |-- location: string (nullable = true)\n",
      " |-- reply_to: long (nullable = true)\n",
      " |-- userId: long (nullable = true)\n",
      " |-- filtered: array (nullable = true)\n",
      " |    |-- element: string (containsNull = true)\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "6737"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cleanData = cleanTweetsDF.drop('hashtags', 'is_verified', 'words', 'text')\n",
    "cleanData.printSchema()\n",
    "cleanData.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleanData.coalesce(1).write.json(\"file:///Users/Laith/Downloads/features_tweets5.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Raw Cell Format",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
